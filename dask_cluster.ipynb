{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage')\n",
    "\n",
    "from main import parser_arguments, regional_extremes_method, local_extremes_method, regional_extremes_minicube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client as daskClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 38063 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">SLURMCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">99699261</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://10.0.30.56:38063/status\" target=\"_blank\">http://10.0.30.56:38063/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 0\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 0\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-cc7be33d-6ce7-49f2-8ebc-ddf1bedaa0d8</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://10.0.30.56:36175\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://10.0.30.56:38063/status\" target=\"_blank\">http://10.0.30.56:38063/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 0\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "SLURMCluster(99699261, 'tcp://10.0.30.56:36175', workers=0, threads=0, memory=0 B)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set distributed scheduler as default\n",
    "import dask\n",
    "dask.config.set(scheduler='distributed')\n",
    "\n",
    "cluster = SLURMCluster(\n",
    "    queue='work',                  # Specify the SLURM queue\n",
    "    processes=1,                     # Number of processes per job\n",
    "    cores=1,                          # Number of cores per job\n",
    "    memory='50GB',                    # Memory per job\n",
    "    walltime='15:00:00',              # Job duration (hh:mm:ss)\n",
    "    job_script_prologue=[\n",
    "        'module load BGC-easybuilded',\n",
    "        'module load  GCC',\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale up the number of workers\n",
    "#cluster.scale(jobs=20)  # Adjust the number of jobs/workers\n",
    "cluster.adapt(minimum=0, maximum=30)\n",
    "\n",
    "# Create a Dask client that connects to the cluster\n",
    "client = daskClient(cluster)\n",
    "\n",
    "# Check cluster status\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(id=None, name=None, index='pei_180', compute_variance=False, region='globe', time_resolution=5, n_components=3, n_samples=100, n_eco_clusters=25, kernel_pca=False, saving_path=None, path_load_experiment=None, method='regional')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "\n",
    "# Remove Jupyter's arguments before parsing your own\n",
    "sys.argv = sys.argv[:1]\n",
    "\n",
    "\n",
    "args = parser_arguments().parse_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-20 14:38:27] Initialisation of a new model, no path provided for an existing model.\n",
      "[2024-12-20 14:38:27] The saving path is: /Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/experiments/2024-12-20_14:38:27_deep_extreme_global/EVI_EN\n",
      "[2024-12-20 14:38:27] args saved, path: /Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/experiments/2024-12-20_14:38:27_deep_extreme_global/EVI_EN/args.json\n",
      "[2024-12-20 14:38:27] start of the preprocess\n",
      "/Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/experiments/2024-12-20_14:38:27_deep_extreme_global/EVI_EN/temp_file.zarr\n",
      "[2024-12-20 14:38:27] Data not found at /Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/experiments/2024-12-20_14:38:27_deep_extreme_global/EVI_EN/temp_file.zarr\n",
      "count: 40000\n",
      "[2024-12-20 14:38:27] Loading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/dask/base.py:1103: UserWarning: Running on a single-machine scheduler when a distributed client is active might lead to unexpected results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 19m 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 2.04 GiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-20 15:48:00] temp_file computed and saved.\n",
      "/Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/experiments/2024-12-20_14:38:27_deep_extreme_global/EVI_EN/temp_file.zarr\n",
      "[2024-12-20 15:48:00] Data not found at /Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/experiments/2024-12-20_14:38:27_deep_extreme_global/EVI_EN/temp_file.zarr\n",
      "[2024-12-20 15:48:01] Dataset loaded.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Data not loaded.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m UPPER_QUANTILES_LEVEL \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0.95\u001b[39m, \u001b[38;5;241m0.975\u001b[39m, \u001b[38;5;241m0.99\u001b[39m])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregional\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;66;03m# Apply the regional extremes method\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     \u001b[43mregional_extremes_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mLOWER_QUANTILES_LEVEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mUPPER_QUANTILES_LEVEL\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# regional_extremes_minicube(args, (LOWER_QUANTILES_LEVEL, UPPER_QUANTILES_LEVEL))\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Apply the uniform threshold method\u001b[39;00m\n",
      "File \u001b[0;32m/Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/main.py:700\u001b[0m, in \u001b[0;36mregional_extremes_method\u001b[0;34m(args, quantile_levels)\u001b[0m\n\u001b[1;32m    693\u001b[0m dataset \u001b[38;5;241m=\u001b[39m create_handler(\n\u001b[1;32m    694\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    695\u001b[0m     loader\u001b[38;5;241m=\u001b[39mloader,\n\u001b[1;32m    696\u001b[0m     saver\u001b[38;5;241m=\u001b[39msaver,\n\u001b[1;32m    697\u001b[0m     n_samples\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mn_samples,  \u001b[38;5;66;03m# args.n_samples,  # all the dataset\u001b[39;00m\n\u001b[1;32m    698\u001b[0m )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;66;03m# Load and preprocess the dataset\u001b[39;00m\n\u001b[0;32m--> 700\u001b[0m data_subset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[38;5;66;03m# Fit the PCA on the data\u001b[39;00m\n\u001b[1;32m    702\u001b[0m extremes_processor\u001b[38;5;241m.\u001b[39mcompute_pca_and_transform(scaled_data\u001b[38;5;241m=\u001b[39mdata_subset)\n",
      "File \u001b[0;32m/Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/datahandlers/sentinel2.py:388\u001b[0m, in \u001b[0;36mEarthnetDatasetHandler.preprocess_data\u001b[0;34m(self, scale, reduce_temporal_resolution, return_time_serie, remove_nan, process_entire_minicube)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_specific_loading()\n\u001b[0;32m--> 388\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter_dataset_specific\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# useless, legacy...\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariable_name]\n\u001b[1;32m    391\u001b[0m printt(\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputation on the entire dataset. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msizes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m )\n",
      "File \u001b[0;32m/Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/datahandlers/sentinel2.py:203\u001b[0m, in \u001b[0;36mEarthnetDatasetHandler.filter_dataset_specific\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_dataset_specific\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    200\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Standarize the ecological xarray. Remove irrelevant area, and reshape for the PCA.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData not loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# Assert dimensions are as expected after loading and transformation\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    207\u001b[0m         dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msizes \u001b[38;5;28;01mfor\u001b[39;00m dim \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    208\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDimension missing. dimension are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Data not loaded."
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Remove Jupyter's arguments before parsing your own\n",
    "sys.argv = sys.argv[:1]\n",
    "args = parser_arguments().parse_args()\n",
    "args.name = \"deep_extreme_global\"\n",
    "args.index = \"EVI_EN\"\n",
    "args.k_pca = False\n",
    "args.n_samples = 40000\n",
    "args.n_components = 3\n",
    "args.n_eco_clusters = 50\n",
    "args.compute_variance = False\n",
    "args.method = \"regional\"\n",
    "args.start_year = 2000\n",
    "args.is_generic_xarray_dataset = False\n",
    "\n",
    "# args.path_load_experiment = \"/Net/Groups/BGI/scratch/crobin/PythonProjects/ExtremesProject/RegionalExtremesPackage/experiments/2024-12-12_11:52:00_deep_extreme_HR\"\n",
    "\n",
    "LOWER_QUANTILES_LEVEL = np.array([0.01, 0.025, 0.05])\n",
    "UPPER_QUANTILES_LEVEL = np.array([0.95, 0.975, 0.99])\n",
    "if args.method == \"regional\":\n",
    "    # Apply the regional extremes method\n",
    "    regional_extremes_method(args, (LOWER_QUANTILES_LEVEL, UPPER_QUANTILES_LEVEL))\n",
    "    # regional_extremes_minicube(args, (LOWER_QUANTILES_LEVEL, UPPER_QUANTILES_LEVEL))\n",
    "elif args.method == \"local\":\n",
    "    # Apply the uniform threshold method\n",
    "    local_extremes_method(args, (LOWER_QUANTILES_LEVEL, UPPER_QUANTILES_LEVEL))\n",
    "elif args.method == \"global\":\n",
    "    raise NotImplementedError(\"the global method is not yet implemented.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m      2\u001b[0m cluster\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExtremesEnv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
