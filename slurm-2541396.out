2024-12-09 18:42:56,550 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.30.53:34779'
2024-12-09 18:42:56,566 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.30.53:32953'
2024-12-09 18:42:56,569 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.30.53:37621'
2024-12-09 18:42:56,584 - distributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.30.53:42273'
2024-12-09 18:42:57,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-vcubo3z1', purging
2024-12-09 18:42:57,101 - distributed.diskutils - INFO - Found stale lock file and directory '/tmp/dask-scratch-space/worker-3_2iegaz', purging
2024-12-09 18:42:57,514 - distributed.worker - INFO -       Start worker at:     tcp://10.0.30.53:44701
2024-12-09 18:42:57,514 - distributed.worker - INFO -          Listening to:     tcp://10.0.30.53:44701
2024-12-09 18:42:57,514 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-3
2024-12-09 18:42:57,514 - distributed.worker - INFO -          dashboard at:           10.0.30.53:39057
2024-12-09 18:42:57,514 - distributed.worker - INFO - Waiting to connect to:     tcp://10.0.30.56:33243
2024-12-09 18:42:57,514 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:57,514 - distributed.worker - INFO -               Threads:                          1
2024-12-09 18:42:57,514 - distributed.worker - INFO -                Memory:                   1.16 GiB
2024-12-09 18:42:57,514 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pq1n1spf
2024-12-09 18:42:57,514 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:57,618 - distributed.worker - INFO -       Start worker at:     tcp://10.0.30.53:35741
2024-12-09 18:42:57,618 - distributed.worker - INFO -          Listening to:     tcp://10.0.30.53:35741
2024-12-09 18:42:57,618 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-0
2024-12-09 18:42:57,619 - distributed.worker - INFO -          dashboard at:           10.0.30.53:32919
2024-12-09 18:42:57,619 - distributed.worker - INFO - Waiting to connect to:     tcp://10.0.30.56:33243
2024-12-09 18:42:57,619 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:57,619 - distributed.worker - INFO -               Threads:                          1
2024-12-09 18:42:57,619 - distributed.worker - INFO -                Memory:                   1.16 GiB
2024-12-09 18:42:57,619 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-piuufbg8
2024-12-09 18:42:57,619 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:57,709 - distributed.worker - INFO -       Start worker at:     tcp://10.0.30.53:41281
2024-12-09 18:42:57,709 - distributed.worker - INFO -          Listening to:     tcp://10.0.30.53:41281
2024-12-09 18:42:57,709 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-1
2024-12-09 18:42:57,709 - distributed.worker - INFO -          dashboard at:           10.0.30.53:37001
2024-12-09 18:42:57,709 - distributed.worker - INFO - Waiting to connect to:     tcp://10.0.30.56:33243
2024-12-09 18:42:57,709 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:57,709 - distributed.worker - INFO -               Threads:                          1
2024-12-09 18:42:57,709 - distributed.worker - INFO -                Memory:                   1.16 GiB
2024-12-09 18:42:57,709 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-pux7drc1
2024-12-09 18:42:57,709 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:57,792 - distributed.worker - INFO -       Start worker at:     tcp://10.0.30.53:43145
2024-12-09 18:42:57,792 - distributed.worker - INFO -          Listening to:     tcp://10.0.30.53:43145
2024-12-09 18:42:57,792 - distributed.worker - INFO -           Worker name:           SLURMCluster-0-2
2024-12-09 18:42:57,793 - distributed.worker - INFO -          dashboard at:           10.0.30.53:34251
2024-12-09 18:42:57,793 - distributed.worker - INFO - Waiting to connect to:     tcp://10.0.30.56:33243
2024-12-09 18:42:57,793 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:57,793 - distributed.worker - INFO -               Threads:                          1
2024-12-09 18:42:57,793 - distributed.worker - INFO -                Memory:                   1.16 GiB
2024-12-09 18:42:57,793 - distributed.worker - INFO -       Local Directory: /tmp/dask-scratch-space/worker-_v6iqwtq
2024-12-09 18:42:57,793 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:59,415 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-12-09 18:42:59,417 - distributed.worker - INFO -         Registered to:     tcp://10.0.30.56:33243
2024-12-09 18:42:59,417 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:59,418 - distributed.core - INFO - Starting established connection to tcp://10.0.30.56:33243
2024-12-09 18:42:59,439 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-12-09 18:42:59,441 - distributed.worker - INFO -         Registered to:     tcp://10.0.30.56:33243
2024-12-09 18:42:59,441 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:59,444 - distributed.core - INFO - Starting established connection to tcp://10.0.30.56:33243
2024-12-09 18:42:59,446 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-12-09 18:42:59,447 - distributed.worker - INFO -         Registered to:     tcp://10.0.30.56:33243
2024-12-09 18:42:59,447 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:59,449 - distributed.core - INFO - Starting established connection to tcp://10.0.30.56:33243
2024-12-09 18:42:59,454 - distributed.worker - INFO - Starting Worker plugin shuffle
2024-12-09 18:42:59,455 - distributed.worker - INFO -         Registered to:     tcp://10.0.30.56:33243
2024-12-09 18:42:59,455 - distributed.worker - INFO - -------------------------------------------------
2024-12-09 18:42:59,456 - distributed.core - INFO - Starting established connection to tcp://10.0.30.56:33243
2024-12-09 18:43:01,188 - distributed.worker - INFO - Stopping worker at tcp://10.0.30.53:43145. Reason: scheduler-remove-worker
2024-12-09 18:43:01,192 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.0.30.53:37621'. Reason: scheduler-remove-worker
2024-12-09 18:43:01,193 - distributed.worker - INFO - Removing Worker plugin shuffle
2024-12-09 18:43:01,194 - distributed.worker - ERROR - Failed to communicate with scheduler during heartbeat.
Traceback (most recent call last):
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/core.py", line 1485, in connect
    return await self._connect(addr=addr, timeout=timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/core.py", line 1429, in _connect
    comm = await connect(
           ^^^^^^^^^^^^^^
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/comm/core.py", line 377, in connect
    handshake = await comm.read()
                ^^^^^^^^^^^^^^^^^
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/comm/tcp.py", line 225, in read
    frames_nosplit_nbytes_bin = await stream.read_bytes(fmt_size)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/core.py", line 1476, in connect
    async with asyncio.timeout(math.inf) as scope:
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/asyncio/timeouts.py", line 115, in __aexit__
    raise TimeoutError from exc_val
TimeoutError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/worker.py", line 1269, in heartbeat
    response = await retry_operation(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/utils_comm.py", line 441, in retry_operation
    return await retry(
           ^^^^^^^^^^^^
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/utils_comm.py", line 420, in retry
    return await coro()
           ^^^^^^^^^^^^
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/core.py", line 1256, in send_recv_from_rpc
    comm = await self.pool.connect(self.addr)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Net/Groups/BGI/scratch/crobin/miniconda3/envs/ExtremesEnv2/lib/python3.12/site-packages/distributed/core.py", line 1497, in connect
    raise CommClosedError(reason)
distributed.comm.core.CommClosedError: ConnectionPool closing.
2024-12-09 18:43:01,216 - distributed.nanny - INFO - Worker closed
2024-12-09 18:43:01,216 - distributed.core - INFO - Connection to tcp://10.0.30.56:33243 has been closed.
2024-12-09 18:43:01,493 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.
2024-12-09 18:43:01,494 - distributed.worker - INFO - Stopping worker at tcp://10.0.30.53:44701. Reason: worker-heartbeat-missing
2024-12-09 18:43:01,499 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.0.30.53:42273'. Reason: worker-heartbeat-missing
2024-12-09 18:43:01,500 - distributed.worker - INFO - Removing Worker plugin shuffle
2024-12-09 18:43:01,502 - distributed.core - INFO - Connection to tcp://10.0.30.56:33243 has been closed.
2024-12-09 18:43:01,504 - distributed.nanny - INFO - Worker closed
2024-12-09 18:43:01,504 - distributed.worker - WARNING - Scheduler was unaware of this worker; shutting down.
2024-12-09 18:43:01,505 - distributed.worker - INFO - Stopping worker at tcp://10.0.30.53:41281. Reason: worker-heartbeat-missing
2024-12-09 18:43:01,508 - distributed.nanny - INFO - Closing Nanny gracefully at 'tcp://10.0.30.53:32953'. Reason: worker-heartbeat-missing
2024-12-09 18:43:01,509 - distributed.worker - INFO - Removing Worker plugin shuffle
2024-12-09 18:43:01,511 - distributed.core - INFO - Connection to tcp://10.0.30.56:33243 has been closed.
2024-12-09 18:43:01,512 - distributed.nanny - INFO - Worker closed
slurmstepd: error: *** JOB 2541396 ON node-r6-he33 CANCELLED AT 2024-12-09T18:43:02 ***
